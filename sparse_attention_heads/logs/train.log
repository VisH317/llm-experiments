[INFO ]  test
[INFO ]  test (2023-12-19 08:15:22,072)
[INFO ]  Loading dataset (2023-12-19 08:15:22,073)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:15:22,076)
[DEBUG]  https://huggingface.co:443 "GET /api/datasets/wikipedia HTTP/1.1" 200 13816 (2023-12-19 08:15:22,202)
[DEBUG]  Starting new HTTPS connection (1): s3.amazonaws.com:443 (2023-12-19 08:15:22,207)
[DEBUG]  https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/wikipedia/wikipedia.py HTTP/1.1" 200 0 (2023-12-19 08:15:22,364)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:15:22,370)
[DEBUG]  https://huggingface.co:443 "HEAD /datasets/wikipedia/resolve/main/wikipedia.py HTTP/1.1" 200 0 (2023-12-19 08:15:22,473)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:15:22,476)
[DEBUG]  https://huggingface.co:443 "GET /datasets/wikipedia/resolve/main/wikipedia.py HTTP/1.1" 200 35871 (2023-12-19 08:15:22,563)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:15:22,599)
[DEBUG]  https://huggingface.co:443 "HEAD /datasets/wikipedia/resolve/main/dataset_infos.json HTTP/1.1" 200 0 (2023-12-19 08:15:22,683)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:15:22,686)
[DEBUG]  https://huggingface.co:443 "GET /datasets/wikipedia/resolve/main/dataset_infos.json HTTP/1.1" 200 30394 (2023-12-19 08:15:22,792)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:15:22,803)
[DEBUG]  https://huggingface.co:443 "HEAD /datasets/wikipedia/resolve/main/README.md HTTP/1.1" 200 0 (2023-12-19 08:15:22,894)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:15:22,897)
[DEBUG]  https://huggingface.co:443 "GET /datasets/wikipedia/resolve/main/README.md HTTP/1.1" 200 16258 (2023-12-19 08:15:22,979)
[DEBUG]  Using selector: EpollSelector (2023-12-19 08:15:23,622)
[DEBUG]  Retrieve file size for https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json (2023-12-19 08:15:23,626)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json> read: 0 - 15337 (2023-12-19 08:15:23,795)
[DEBUG]  Fetch range for <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json>: 0-15337 (2023-12-19 08:15:23,796)
[DEBUG]  https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json : bytes=0-15336 (2023-12-19 08:15:23,796)
[INFO ]  Dataset loaded! (2023-12-19 08:15:23,923)
[INFO ]  set up vocab + parser (2023-12-19 08:15:23,924)
[INFO ]  Loading dataset (2023-12-19 08:16:28,730)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:16:28,733)
[DEBUG]  https://huggingface.co:443 "GET /api/datasets/wikipedia HTTP/1.1" 200 13816 (2023-12-19 08:16:29,083)
[DEBUG]  Starting new HTTPS connection (1): s3.amazonaws.com:443 (2023-12-19 08:16:29,087)
[DEBUG]  https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/wikipedia/wikipedia.py HTTP/1.1" 200 0 (2023-12-19 08:16:29,796)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:16:29,806)
[DEBUG]  https://huggingface.co:443 "HEAD /datasets/wikipedia/resolve/main/wikipedia.py HTTP/1.1" 200 0 (2023-12-19 08:16:29,968)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:16:29,974)
[DEBUG]  https://huggingface.co:443 "HEAD /datasets/wikipedia/resolve/main/dataset_infos.json HTTP/1.1" 200 0 (2023-12-19 08:16:30,594)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:16:30,600)
[DEBUG]  https://huggingface.co:443 "HEAD /datasets/wikipedia/resolve/main/README.md HTTP/1.1" 200 0 (2023-12-19 08:16:30,853)
[DEBUG]  Using selector: EpollSelector (2023-12-19 08:16:31,188)
[DEBUG]  Retrieve file size for https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json (2023-12-19 08:16:31,192)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json> read: 0 - 15337 (2023-12-19 08:16:31,315)
[DEBUG]  Fetch range for <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json>: 0-15337 (2023-12-19 08:16:31,317)
[DEBUG]  https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json : bytes=0-15336 (2023-12-19 08:16:31,317)
[INFO ]  Dataset loaded! (2023-12-19 08:16:31,408)
[INFO ]  set up vocab + parser (2023-12-19 08:16:31,409)
[INFO ]  Loading dataset (2023-12-19 08:17:06,416)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:17:06,420)
[DEBUG]  https://huggingface.co:443 "GET /api/datasets/wikipedia HTTP/1.1" 200 13816 (2023-12-19 08:17:07,071)
[DEBUG]  Starting new HTTPS connection (1): s3.amazonaws.com:443 (2023-12-19 08:17:07,077)
[DEBUG]  https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/wikipedia/wikipedia.py HTTP/1.1" 200 0 (2023-12-19 08:17:08,029)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:17:08,036)
[DEBUG]  https://huggingface.co:443 "HEAD /datasets/wikipedia/resolve/main/wikipedia.py HTTP/1.1" 200 0 (2023-12-19 08:17:08,539)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:17:08,547)
[DEBUG]  https://huggingface.co:443 "HEAD /datasets/wikipedia/resolve/main/dataset_infos.json HTTP/1.1" 200 0 (2023-12-19 08:17:09,215)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:17:09,223)
[DEBUG]  https://huggingface.co:443 "HEAD /datasets/wikipedia/resolve/main/README.md HTTP/1.1" 200 0 (2023-12-19 08:17:09,536)
[DEBUG]  Using selector: EpollSelector (2023-12-19 08:17:09,913)
[DEBUG]  Retrieve file size for https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json (2023-12-19 08:17:09,917)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json> read: 0 - 15337 (2023-12-19 08:17:11,015)
[DEBUG]  Fetch range for <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json>: 0-15337 (2023-12-19 08:17:11,016)
[DEBUG]  https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json : bytes=0-15336 (2023-12-19 08:17:11,017)
[INFO ]  Dataset loaded! (2023-12-19 08:17:11,052)
[INFO ]  set up vocab + parser (2023-12-19 08:17:11,054)
[INFO ]  Loading dataset (2023-12-19 08:17:44,546)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:17:44,549)
[DEBUG]  https://huggingface.co:443 "GET /api/datasets/wikipedia HTTP/1.1" 200 13816 (2023-12-19 08:17:44,705)
[DEBUG]  Starting new HTTPS connection (1): s3.amazonaws.com:443 (2023-12-19 08:17:44,709)
[DEBUG]  https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/wikipedia/wikipedia.py HTTP/1.1" 200 0 (2023-12-19 08:17:44,865)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:17:44,872)
[DEBUG]  https://huggingface.co:443 "HEAD /datasets/wikipedia/resolve/main/wikipedia.py HTTP/1.1" 200 0 (2023-12-19 08:17:44,962)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:17:44,967)
[DEBUG]  https://huggingface.co:443 "HEAD /datasets/wikipedia/resolve/main/dataset_infos.json HTTP/1.1" 200 0 (2023-12-19 08:17:45,053)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:17:45,059)
[DEBUG]  https://huggingface.co:443 "HEAD /datasets/wikipedia/resolve/main/README.md HTTP/1.1" 200 0 (2023-12-19 08:17:45,161)
[DEBUG]  Using selector: EpollSelector (2023-12-19 08:17:45,470)
[DEBUG]  Retrieve file size for https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json (2023-12-19 08:17:45,473)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json> read: 0 - 15337 (2023-12-19 08:17:45,542)
[DEBUG]  Fetch range for <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json>: 0-15337 (2023-12-19 08:17:45,543)
[DEBUG]  https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json : bytes=0-15336 (2023-12-19 08:17:45,543)
[INFO ]  Dataset loaded! (2023-12-19 08:17:45,569)
[INFO ]  set up vocab + parser (2023-12-19 08:17:45,570)
[INFO ]  Loading dataset (2023-12-19 08:18:39,149)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:18:39,152)
[INFO ]  set up vocab + parser (2023-12-19 08:19:21,472)
[INFO ]  set up vocab + parser (2023-12-19 08:22:22,432)
[INFO ]  set up vocab + parser (2023-12-19 08:23:06,127)
[INFO ]  initializing sparse heads transformer (2023-12-19 08:23:06,133)
[INFO ]  set up vocab + parser (2023-12-19 08:25:40,668)
[INFO ]  initializing sparse heads transformer (2023-12-19 08:25:40,675)
[INFO ]  set up vocab + parser (2023-12-19 08:26:08,730)
[INFO ]  initializing sparse heads transformer (2023-12-19 08:26:08,735)
[INFO ]  set up vocab + parser (2023-12-19 08:26:28,322)
[INFO ]  initializing sparse heads transformer (2023-12-19 08:26:28,327)
[INFO ]  set up vocab + parser (2023-12-19 08:26:53,799)
[INFO ]  initializing sparse heads transformer (2023-12-19 08:26:53,804)
[INFO ]  Loading epoch 0... (2023-12-19 08:26:57,705)
[INFO ]  Loading dataset (2023-12-19 08:27:11,874)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:27:11,877)
[DEBUG]  https://huggingface.co:443 "GET /api/datasets/wikipedia HTTP/1.1" 200 13816 (2023-12-19 08:27:12,015)
[DEBUG]  Starting new HTTPS connection (1): s3.amazonaws.com:443 (2023-12-19 08:27:12,018)
[DEBUG]  https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/wikipedia/wikipedia.py HTTP/1.1" 200 0 (2023-12-19 08:27:12,175)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:27:12,179)
[DEBUG]  https://huggingface.co:443 "HEAD /datasets/wikipedia/resolve/main/wikipedia.py HTTP/1.1" 200 0 (2023-12-19 08:27:12,268)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:27:12,273)
[DEBUG]  https://huggingface.co:443 "HEAD /datasets/wikipedia/resolve/main/dataset_infos.json HTTP/1.1" 200 0 (2023-12-19 08:27:12,358)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:27:12,362)
[DEBUG]  https://huggingface.co:443 "HEAD /datasets/wikipedia/resolve/main/README.md HTTP/1.1" 200 0 (2023-12-19 08:27:12,444)
[DEBUG]  Using selector: EpollSelector (2023-12-19 08:27:12,737)
[DEBUG]  Retrieve file size for https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json (2023-12-19 08:27:12,740)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json> read: 0 - 15337 (2023-12-19 08:27:12,863)
[DEBUG]  Fetch range for <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json>: 0-15337 (2023-12-19 08:27:12,864)
[DEBUG]  https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json : bytes=0-15336 (2023-12-19 08:27:12,864)
[INFO ]  Dataset loaded! (2023-12-19 08:27:12,888)
[INFO ]  set up vocab + parser (2023-12-19 08:27:12,889)
[INFO ]  initializing sparse heads transformer (2023-12-19 08:27:12,895)
[INFO ]  Loading epoch 0... (2023-12-19 08:27:16,620)
[WARNI]  Too many dataloader workers: 4 (max is dataset.n_shards=1). Stopping 3 dataloader workers. (2023-12-19 08:27:16,711)
[DEBUG]  Using selector: EpollSelector (2023-12-19 08:27:16,716)
[DEBUG]  Retrieve file size for https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow (2023-12-19 08:27:16,729)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow> read: 0 - 4 (2023-12-19 08:27:17,505)
[DEBUG]  Fetch range for <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow>: 0-5242884 (2023-12-19 08:27:17,507)
[DEBUG]  https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow : bytes=0-5242883 (2023-12-19 08:27:17,508)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow> read: 4 - 8 (2023-12-19 08:27:19,306)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow> read: 8 - 560 (2023-12-19 08:27:19,306)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow> read: 560 - 564 (2023-12-19 08:27:19,313)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow> read: 564 - 568 (2023-12-19 08:27:19,314)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow> read: 568 - 912 (2023-12-19 08:27:19,314)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow> read: 912 - 87292496 (2023-12-19 08:27:19,314)
[DEBUG]  Fetch range for <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow>: 912-92535376 (2023-12-19 08:27:19,316)
[DEBUG]  https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow : bytes=912-92535375 (2023-12-19 08:27:19,316)
[INFO ]  Loading dataset (2023-12-19 08:28:33,863)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:28:33,867)
[DEBUG]  https://huggingface.co:443 "GET /api/datasets/wikipedia HTTP/1.1" 200 13816 (2023-12-19 08:28:35,925)
[DEBUG]  Starting new HTTPS connection (1): s3.amazonaws.com:443 (2023-12-19 08:28:35,931)
[DEBUG]  https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/wikipedia/wikipedia.py HTTP/1.1" 200 0 (2023-12-19 08:28:36,849)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:28:36,854)
[DEBUG]  https://huggingface.co:443 "HEAD /datasets/wikipedia/resolve/main/wikipedia.py HTTP/1.1" 200 0 (2023-12-19 08:28:37,058)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:28:37,065)
[DEBUG]  https://huggingface.co:443 "HEAD /datasets/wikipedia/resolve/main/dataset_infos.json HTTP/1.1" 200 0 (2023-12-19 08:28:38,029)
[DEBUG]  Starting new HTTPS connection (1): huggingface.co:443 (2023-12-19 08:28:38,035)
[DEBUG]  https://huggingface.co:443 "HEAD /datasets/wikipedia/resolve/main/README.md HTTP/1.1" 200 0 (2023-12-19 08:28:38,145)
[DEBUG]  Using selector: EpollSelector (2023-12-19 08:28:38,510)
[DEBUG]  Retrieve file size for https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json (2023-12-19 08:28:38,514)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json> read: 0 - 15337 (2023-12-19 08:28:38,586)
[DEBUG]  Fetch range for <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json>: 0-15337 (2023-12-19 08:28:38,587)
[DEBUG]  https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/dataset_info.json : bytes=0-15336 (2023-12-19 08:28:38,588)
[INFO ]  Dataset loaded! (2023-12-19 08:28:38,616)
[INFO ]  set up vocab + parser (2023-12-19 08:28:38,617)
[INFO ]  initializing sparse heads transformer (2023-12-19 08:28:38,624)
[INFO ]  Loading epoch 0... (2023-12-19 08:28:42,859)
[WARNI]  Too many dataloader workers: 4 (max is dataset.n_shards=1). Stopping 3 dataloader workers. (2023-12-19 08:28:42,947)
[DEBUG]  Using selector: EpollSelector (2023-12-19 08:28:42,954)
[DEBUG]  Retrieve file size for https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow (2023-12-19 08:28:42,975)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow> read: 0 - 4 (2023-12-19 08:28:43,165)
[DEBUG]  Fetch range for <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow>: 0-5242884 (2023-12-19 08:28:43,166)
[DEBUG]  https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow : bytes=0-5242883 (2023-12-19 08:28:43,166)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow> read: 4 - 8 (2023-12-19 08:28:44,894)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow> read: 8 - 560 (2023-12-19 08:28:44,895)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow> read: 560 - 564 (2023-12-19 08:28:44,895)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow> read: 564 - 568 (2023-12-19 08:28:44,896)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow> read: 568 - 912 (2023-12-19 08:28:44,896)
[DEBUG]  <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow> read: 912 - 87292496 (2023-12-19 08:28:44,897)
[DEBUG]  Fetch range for <File-like object HTTPFileSystem, https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow>: 912-92535376 (2023-12-19 08:28:44,898)
[DEBUG]  https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20220301.en/2.0.0/wikipedia-train.arrow : bytes=912-92535375 (2023-12-19 08:28:44,898)
[INFO ]  Loading dataset (2023-12-19 08:32:05,663)
[INFO ]  Loading dataset (2023-12-19 08:32:45,707)
[INFO ]  Loading dataset (2023-12-19 08:33:26,466)
[INFO ]  Dataset loaded! (2023-12-19 08:33:30,034)
[INFO ]  set up vocab + parser (2023-12-19 08:33:30,035)
[INFO ]  initializing sparse heads transformer (2023-12-19 08:33:30,041)
[INFO ]  Loading dataset (2023-12-19 08:33:43,941)
[INFO ]  Dataset loaded! (2023-12-19 08:33:44,859)
[INFO ]  Loading dataset (2023-12-19 08:35:07,371)
[INFO ]  Loading dataset (2023-12-19 08:36:04,476)
[INFO ]  Loading dataset (2023-12-19 08:37:01,294)
[INFO ]  Dataset loaded! (2023-12-19 08:37:03,222)
[INFO ]  set up vocab + parser (2023-12-19 08:37:03,223)
[INFO ]  initializing sparse heads transformer (2023-12-19 08:37:03,228)
[INFO ]  Loading dataset (2023-12-19 08:37:15,341)
[INFO ]  Dataset loaded! (2023-12-19 08:37:18,944)
[INFO ]  Loading dataset (2023-12-19 08:40:58,925)
[INFO ]  Loading dataset (2023-12-19 08:41:35,154)
[INFO ]  Loading dataset (2023-12-19 08:46:14,094)
[INFO ]  Loading dataset (2023-12-19 08:46:36,030)
[INFO ]  Dataset loaded! (2023-12-19 08:46:37,048)
[INFO ]  set up vocab + parser (2023-12-19 08:46:37,049)
[INFO ]  initializing sparse heads transformer (2023-12-19 08:46:37,056)
[INFO ]  Loading epoch 0... (2023-12-19 08:46:41,188)
[WARNI]  Too many dataloader workers: 4 (max is dataset.n_shards=1). Stopping 3 dataloader workers. (2023-12-19 08:46:41,280)
[INFO ]  Loading dataset (2023-12-19 08:46:59,800)
[INFO ]  Dataset loaded! (2023-12-19 08:47:00,701)
[INFO ]  set up vocab + parser (2023-12-19 08:47:00,703)
[INFO ]  initializing sparse heads transformer (2023-12-19 08:47:00,713)
[INFO ]  Loading dataset (2023-12-19 08:49:13,299)
[INFO ]  Loading dataset (2023-12-19 08:49:49,497)
[INFO ]  Loading dataset (2023-12-19 08:51:12,313)
[INFO ]  Dataset loaded! (2023-12-19 08:51:14,890)
[INFO ]  set up vocab + parser (2023-12-19 08:51:14,892)
[INFO ]  initializing sparse heads transformer (2023-12-19 08:51:14,898)
[INFO ]  Loading dataset (2023-12-19 09:34:25,383)
[INFO ]  Loading dataset (2023-12-19 09:35:02,152)
[INFO ]  Loading dataset (2023-12-19 09:35:54,067)
[INFO ]  Loading dataset (2023-12-19 09:37:21,421)
[INFO ]  Loading dataset (2023-12-19 09:38:02,517)
[INFO ]  Dataset loaded! (2023-12-19 09:38:03,701)
[INFO ]  set up vocab + parser (2023-12-19 09:38:03,702)
[INFO ]  initializing sparse heads transformer (2023-12-19 09:38:03,710)
[INFO ]  Loading dataset (2023-12-19 09:38:59,697)
[INFO ]  Dataset loaded! (2023-12-19 09:39:00,974)
[INFO ]  set up vocab + parser (2023-12-19 09:39:00,975)
[INFO ]  initializing sparse heads transformer (2023-12-19 09:39:00,981)
[INFO ]  Loading epoch 0... (2023-12-19 09:39:05,399)
[WARNI]  Too many dataloader workers: 4 (max is dataset.n_shards=1). Stopping 3 dataloader workers. (2023-12-19 09:39:05,610)
[INFO ]  Loading dataset (2023-12-19 09:39:29,793)
[INFO ]  Dataset loaded! (2023-12-19 09:39:30,984)
[INFO ]  set up vocab + parser (2023-12-19 09:39:30,986)
[INFO ]  initializing sparse heads transformer (2023-12-19 09:39:30,996)
[INFO ]  Loading epoch 0... (2023-12-19 09:39:35,690)
[WARNI]  Too many dataloader workers: 4 (max is dataset.n_shards=1). Stopping 3 dataloader workers. (2023-12-19 09:39:35,780)
[INFO ]  Loading dataset (2023-12-19 09:39:55,001)
[INFO ]  Dataset loaded! (2023-12-19 09:39:56,149)
[INFO ]  Loading dataset (2023-12-19 09:40:06,759)
[INFO ]  Dataset loaded! (2023-12-19 09:40:11,192)
[INFO ]  set up vocab + parser (2023-12-19 09:40:11,193)
[INFO ]  initializing sparse heads transformer (2023-12-19 09:40:11,199)
[INFO ]  Loading dataset (2023-12-19 09:40:32,579)
[INFO ]  Dataset loaded! (2023-12-19 09:40:34,324)
[INFO ]  set up vocab + parser (2023-12-19 09:40:34,326)
[INFO ]  initializing sparse heads transformer (2023-12-19 09:40:34,339)
[INFO ]  Loading dataset (2023-12-19 09:41:02,466)
[INFO ]  Dataset loaded! (2023-12-19 09:41:05,345)
[INFO ]  Loading dataset (2023-12-19 09:42:41,265)
[INFO ]  Dataset loaded! (2023-12-19 09:42:42,440)
[INFO ]  Loading dataset (2023-12-19 09:43:09,829)
[INFO ]  Loading dataset (2023-12-19 09:43:48,493)
[INFO ]  Loading dataset (2023-12-19 09:44:07,618)
[INFO ]  Loading dataset (2023-12-19 09:44:48,124)
[INFO ]  Loading dataset (2023-12-19 09:45:59,634)
[INFO ]  Loading dataset (2023-12-19 09:46:42,355)
[INFO ]  Dataset loaded! (2023-12-19 09:46:44,340)
[INFO ]  Loading dataset (2023-12-19 09:48:24,108)
[INFO ]  Dataset loaded! (2023-12-19 09:48:26,828)
[INFO ]  set up vocab + parser (2023-12-19 09:48:26,836)
[INFO ]  initializing sparse heads transformer (2023-12-19 09:48:26,842)
[INFO ]  Loading epoch 0... (2023-12-19 09:48:31,096)
[WARNI]  Too many dataloader workers: 4 (max is dataset.n_shards=1). Stopping 3 dataloader workers. (2023-12-19 09:48:31,223)
[INFO ]  Loading dataset (2023-12-19 09:49:48,053)
[INFO ]  Dataset loaded! (2023-12-19 09:49:49,306)
[INFO ]  set up vocab + parser (2023-12-19 09:49:49,307)
[INFO ]  initializing sparse heads transformer (2023-12-19 09:49:49,316)
[INFO ]  Loading epoch 0... (2023-12-19 09:49:53,211)
[INFO ]  Loading dataset (2023-12-19 09:50:22,617)
[INFO ]  Dataset loaded! (2023-12-19 09:50:24,175)
[INFO ]  set up vocab + parser (2023-12-19 09:50:24,176)
[INFO ]  initializing sparse heads transformer (2023-12-19 09:50:24,181)
[INFO ]  Loading epoch 0... (2023-12-19 09:50:28,519)
[INFO ]  Loading dataset (2023-12-19 09:53:40,689)
[INFO ]  Loading dataset (2023-12-19 09:55:11,397)
[INFO ]  Loading dataset (2023-12-19 09:56:53,745)
[INFO ]  Loading dataset (2023-12-19 09:58:27,620)
[INFO ]  Loading dataset (2023-12-19 09:59:45,616)
[INFO ]  Dataset loaded! (2023-12-19 09:59:47,191)
[INFO ]  set up vocab + parser (2023-12-19 09:59:47,192)
[INFO ]  initializing sparse heads transformer (2023-12-19 09:59:47,203)
[INFO ]  Loading epoch 0... (2023-12-19 09:59:51,311)
[INFO ]  set up vocab + parser (2023-12-19 10:03:27,685)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:03:27,691)
[INFO ]  Loading epoch 0... (2023-12-19 10:03:31,450)
[INFO ]  set up vocab + parser (2023-12-19 10:03:47,609)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:03:47,613)
[INFO ]  Loading epoch 0... (2023-12-19 10:03:50,549)
[INFO ]  batch processed! (2023-12-19 10:03:51,007)
[INFO ]  set up vocab + parser (2023-12-19 10:04:36,111)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:04:36,116)
[INFO ]  Loading epoch 0... (2023-12-19 10:04:39,998)
[INFO ]  batch processed! (2023-12-19 10:04:40,434)
[INFO ]  set up vocab + parser (2023-12-19 10:05:03,065)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:05:03,070)
[INFO ]  Loading epoch 0... (2023-12-19 10:05:07,152)
[INFO ]  batch processed! (2023-12-19 10:05:07,658)
[INFO ]  set up vocab + parser (2023-12-19 10:06:35,378)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:06:35,383)
[INFO ]  Loading epoch 0... (2023-12-19 10:06:39,197)
[INFO ]  batch processed! (2023-12-19 10:06:39,799)
[INFO ]  set up vocab + parser (2023-12-19 10:07:19,599)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:07:19,605)
[INFO ]  set up vocab + parser (2023-12-19 10:07:53,791)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:07:53,796)
[INFO ]  Loading epoch 0... (2023-12-19 10:07:57,123)
[INFO ]  batch processed! (2023-12-19 10:07:57,616)
[INFO ]  set up vocab + parser (2023-12-19 10:16:56,583)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:16:56,588)
[INFO ]  Loading epoch 0... (2023-12-19 10:17:00,615)
[INFO ]  batch processed! (2023-12-19 10:17:01,135)
[INFO ]  set up vocab + parser (2023-12-19 10:17:17,845)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:17:17,853)
[INFO ]  Loading epoch 0... (2023-12-19 10:17:21,902)
[INFO ]  batch processed! (2023-12-19 10:17:28,850)
[INFO ]  set up vocab + parser (2023-12-19 10:19:42,513)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:19:42,519)
[INFO ]  Loading epoch 0... (2023-12-19 10:19:43,518)
[INFO ]  batch processed! (2023-12-19 10:19:44,355)
[INFO ]  set up vocab + parser (2023-12-19 10:22:41,804)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:22:41,810)
[INFO ]  Loading epoch 0... (2023-12-19 10:22:42,891)
[INFO ]  batch processed! (2023-12-19 10:22:43,699)
[INFO ]  set up vocab + parser (2023-12-19 10:27:48,714)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:27:48,720)
[INFO ]  Loading epoch 0... (2023-12-19 10:27:49,761)
[INFO ]  batch processed! (2023-12-19 10:27:50,626)
[INFO ]  set up vocab + parser (2023-12-19 10:31:14,753)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:31:14,760)
[INFO ]  Loading epoch 0... (2023-12-19 10:31:15,775)
[INFO ]  batch processed! (2023-12-19 10:31:16,531)
[INFO ]  set up vocab + parser (2023-12-19 10:34:10,030)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:34:10,035)
[INFO ]  Loading epoch 0... (2023-12-19 10:34:11,060)
[INFO ]  batch processed! (2023-12-19 10:34:11,934)
[INFO ]  set up vocab + parser (2023-12-19 10:35:01,905)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:35:01,911)
[INFO ]  Loading epoch 0... (2023-12-19 10:35:02,997)
[INFO ]  batch processed! (2023-12-19 10:35:03,715)
[INFO ]  set up vocab + parser (2023-12-19 10:36:00,462)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:36:00,469)
[INFO ]  Loading epoch 0... (2023-12-19 10:36:01,518)
[INFO ]  batch processed! (2023-12-19 10:36:02,283)
[INFO ]  set up vocab + parser (2023-12-19 10:36:40,901)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:36:40,908)
[INFO ]  Loading epoch 0... (2023-12-19 10:36:41,963)
[INFO ]  batch processed! (2023-12-19 10:36:42,828)
[INFO ]  set up vocab + parser (2023-12-19 10:41:36,958)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:41:36,964)
[INFO ]  Loading epoch 0... (2023-12-19 10:41:37,982)
[INFO ]  batch processed! (2023-12-19 10:41:38,796)
[INFO ]  set up vocab + parser (2023-12-19 10:42:37,871)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:42:37,877)
[INFO ]  Loading epoch 0... (2023-12-19 10:42:38,917)
[INFO ]  batch processed! (2023-12-19 10:42:39,644)
[INFO ]  set up vocab + parser (2023-12-19 10:49:12,000)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:49:12,006)
[INFO ]  Loading epoch 0... (2023-12-19 10:49:13,005)
[INFO ]  set up vocab + parser (2023-12-19 10:49:52,322)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:49:52,328)
[INFO ]  Loading epoch 0... (2023-12-19 10:49:53,362)
[INFO ]  batch processed! (2023-12-19 10:49:53,480)
[INFO ]  set up vocab + parser (2023-12-19 10:51:12,995)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:51:13,001)
[INFO ]  Loading epoch 0... (2023-12-19 10:51:13,994)
[INFO ]  batch processed! (2023-12-19 10:51:14,117)
[INFO ]  set up vocab + parser (2023-12-19 10:55:11,557)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:55:11,562)
[INFO ]  Loading epoch 0... (2023-12-19 10:55:15,473)
[INFO ]  batch processed! (2023-12-19 10:55:15,561)
[INFO ]  set up vocab + parser (2023-12-19 10:55:41,616)
[INFO ]  initializing sparse heads transformer (2023-12-19 10:55:41,623)
[INFO ]  Loading epoch 0... (2023-12-19 10:55:45,546)
[INFO ]  batch processed! (2023-12-19 10:55:45,740)
[INFO ]  set up vocab + parser (2023-12-19 11:39:19,638)
[INFO ]  initializing sparse heads transformer (2023-12-19 11:39:19,642)
[INFO ]  Loading epoch 0... (2023-12-19 11:39:22,645)
[INFO ]  batch processed! (2023-12-19 11:39:22,712)
[INFO ]  set up vocab + parser (2023-12-19 11:40:25,132)
[INFO ]  initializing sparse heads transformer (2023-12-19 11:40:25,136)
[INFO ]  Loading epoch 0... (2023-12-19 11:40:28,000)
[INFO ]  batch processed! (2023-12-19 11:40:28,143)
[INFO ]  set up vocab + parser (2023-12-19 11:41:03,864)
[INFO ]  initializing sparse heads transformer (2023-12-19 11:41:03,867)
[INFO ]  Loading epoch 0... (2023-12-19 11:41:06,396)
[INFO ]  batch processed! (2023-12-19 11:41:06,474)
